<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Blur Facial con TensorFlow.js</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }
        
        body {
            background: linear-gradient(135deg, #1a2a6c, #b21f1f, #fdbb2d);
            color: white;
            min-height: 100vh;
            padding: 20px;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
        }
        
        header {
            text-align: center;
            padding: 20px 0;
            margin-bottom: 30px;
        }
        
        h1 {
            font-size: 2.5rem;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);
        }
        
        .subtitle {
            font-size: 1.2rem;
            opacity: 0.9;
        }
        
        .content {
            display: flex;
            flex-wrap: wrap;
            gap: 20px;
            margin-bottom: 30px;
        }
        
        .video-section {
            flex: 1;
            min-width: 300px;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 15px;
            padding: 20px;
            backdrop-filter: blur(10px);
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.2);
        }
        
        .video-container {
            position: relative;
            width: 100%;
            height: 0;
            padding-bottom: 75%; /* Relación de aspecto 4:3 */
            margin-bottom: 20px;
            border-radius: 10px;
            overflow: hidden;
            background: #000;
        }
        
        video, canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: cover;
        }
        
        .controls {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            justify-content: center;
            margin-top: 20px;
        }
        
        button {
            padding: 12px 20px;
            border: none;
            border-radius: 50px;
            background: rgba(255, 255, 255, 0.2);
            color: white;
            font-weight: bold;
            cursor: pointer;
            transition: all 0.3s ease;
            backdrop-filter: blur(5px);
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.2);
        }
        
        button:hover {
            background: rgba(255, 255, 255, 0.3);
            transform: translateY(-2px);
        }
        
        button.active {
            background: #4a00e0;
            box-shadow: 0 0 15px rgba(74, 0, 224, 0.5);
        }
        
        .info-section {
            flex: 1;
            min-width: 300px;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 15px;
            padding: 20px;
            backdrop-filter: blur(10px);
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.2);
        }
        
        .info-card {
            background: rgba(255, 255, 255, 0.1);
            border-radius: 10px;
            padding: 15px;
            margin-bottom: 15px;
        }
        
        h2 {
            margin-bottom: 15px;
            font-size: 1.5rem;
            border-bottom: 1px solid rgba(255, 255, 255, 0.2);
            padding-bottom: 10px;
        }
        
        .status {
            display: flex;
            align-items: center;
            margin-bottom: 10px;
        }
        
        .status-dot {
            width: 10px;
            height: 10px;
            border-radius: 50%;
            margin-right: 10px;
        }
        
        .status-dot.active {
            background: #00ff00;
            box-shadow: 0 0 10px #00ff00;
        }
        
        .status-dot.inactive {
            background: #ff0000;
        }
        
        .loading {
            text-align: center;
            padding: 20px;
        }
        
        .spinner {
            border: 4px solid rgba(255, 255, 255, 0.3);
            border-radius: 50%;
            border-top: 4px solid white;
            width: 40px;
            height: 40px;
            animation: spin 1s linear infinite;
            margin: 0 auto 15px;
        }
        
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        
        .stats {
            display: flex;
            justify-content: space-around;
            margin-top: 15px;
            text-align: center;
        }
        
        .stat-item {
            flex: 1;
        }
        
        .stat-value {
            font-size: 1.5rem;
            font-weight: bold;
            color: #4a00e0;
        }
        
        footer {
            text-align: center;
            padding: 20px;
            margin-top: 30px;
            font-size: 0.9rem;
            opacity: 0.7;
        }
        
        @media (max-width: 768px) {
            .content {
                flex-direction: column;
            }
            
            h1 {
                font-size: 2rem;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>Blur Facial con TensorFlow.js</h1>
            <p class="subtitle">Protege tu privacidad desenfocando rostros en tiempo real</p>
        </header>
        
        <div class="content">
            <div class="video-section">
                <div class="video-container">
                    <video id="video" autoplay playsinline></video>
                    <canvas id="output"></canvas>
                </div>
                
                <div class="controls">
                    <button id="startBtn" class="active">Iniciar Cámara</button>
                    <button id="faceBlurBtn">Blur Facial</button>
                    <button id="pixelateBtn">Pixelar Rostros</button>
                    <button id="stopBtn">Detener</button>
                </div>
                
                <div class="stats">
                    <div class="stat-item">
                        <div class="stat-value" id="faceCount">0</div>
                        <div>Rostros Detectados</div>
                    </div>
                    <div class="stat-item">
                        <div class="stat-value" id="fps">0</div>
                        <div>FPS</div>
                    </div>
                </div>
            </div>
            
            <div class="info-section">
                <h2>Estado del Sistema</h2>
                
                <div class="info-card">
                    <div class="status">
                        <div id="cameraStatus" class="status-dot inactive"></div>
                        <span>Cámara: Inactiva</span>
                    </div>
                    <div class="status">
                        <div id="modelStatus" class="status-dot inactive"></div>
                        <span>Modelo TensorFlow: Cargando...</span>
                    </div>
                    <div class="status">
                        <div id="filterStatus" class="status-dot inactive"></div>
                        <span>Filtro: Ninguno</span>
                    </div>
                </div>
                
                <div class="info-card">
                    <h2>Instrucciones</h2>
                    <p>1. Haz clic en "Iniciar Cámara" para comenzar</p>
                    <p>2. Selecciona "Blur Facial" para desenfocar rostros</p>
                    <p>3. Usa "Pixelar Rostros" para un efecto diferente</p>
                    <p>4. Los rostros detectados se muestran en el contador</p>
                </div>
                
                <div class="info-card">
                    <h2>Acerca de los Filtros</h2>
                    <p><strong>Blur Facial:</strong> Aplica desenfoque gaussiano a los rostros detectados</p>
                    <p><strong>Pixelar Rostros:</strong> Convierte los rostros en bloques pixelados</p>
                    <p><strong>Sin Filtro:</strong> Muestra el video original sin modificaciones</p>
                </div>
            </div>
        </div>
        
        <div id="loading" class="loading">
            <div class="spinner"></div>
            <p>Cargando modelos de TensorFlow.js...</p>
        </div>
        
        <footer>
            <p>Implementación de TensorFlow.js para protección de privacidad facial</p>
        </footer>
    </div>

    <!-- Cargar TensorFlow.js y modelos -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.18.0"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface@0.0.7"></script>
    
    <script>
        // Elementos del DOM
        const video = document.getElementById('video');
        const canvas = document.getElementById('output');
        const ctx = canvas.getContext('2d');
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const faceBlurBtn = document.getElementById('faceBlurBtn');
        const pixelateBtn = document.getElementById('pixelateBtn');
        const cameraStatus = document.getElementById('cameraStatus');
        const modelStatus = document.getElementById('modelStatus');
        const filterStatus = document.getElementById('filterStatus');
        const faceCount = document.getElementById('faceCount');
        const fpsCounter = document.getElementById('fps');
        const loading = document.getElementById('loading');
        
        // Variables de estado
        let stream = null;
        let animationId = null;
        let currentFilter = 'none';
        let faceDetectionModel = null;
        let lastTimestamp = 0;
        let frameCount = 0;
        
        // Actualizar estado en la UI
        function updateStatus(element, text, isActive) {
            const statusText = element.parentElement.querySelector('span');
            if (statusText) {
                statusText.textContent = text;
            }
            element.classList.toggle('active', isActive);
            element.classList.toggle('inactive', !isActive);
        }
        
        // Inicializar cámara
        async function initCamera() {
            try {
                loading.style.display = 'block';
                stream = await navigator.mediaDevices.getUserMedia({ 
                    video: { width: 640, height: 480 } 
                });
                
                video.srcObject = stream;
                
                // Configurar canvas
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
                
                updateStatus(cameraStatus, 'Cámara: Activa', true);
                startBtn.classList.remove('active');
                stopBtn.classList.add('active');
                
                // Iniciar procesamiento de video
                processVideo();
                
                loading.style.display = 'none';
            } catch (error) {
                console.error('Error al acceder a la cámara:', error);
                alert('No se pudo acceder a la cámara. Asegúrate de permitir el acceso.');
                loading.style.display = 'none';
            }
        }
        
        // Detener cámara
        function stopCamera() {
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
                stream = null;
            }
            
            if (animationId) {
                cancelAnimationFrame(animationId);
                animationId = null;
            }
            
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            
            updateStatus(cameraStatus, 'Cámara: Inactiva', false);
            updateStatus(filterStatus, 'Filtro: Ninguno', false);
            startBtn.classList.add('active');
            stopBtn.classList.remove('active');
            
            // Resetear botones de filtro
            faceBlurBtn.classList.remove('active');
            pixelateBtn.classList.remove('active');
            
            currentFilter = 'none';
            faceCount.textContent = '0';
            fpsCounter.textContent = '0';
        }
        
        // Cargar modelos de TensorFlow.js
        async function loadModels() {
            try {
                loading.style.display = 'block';
                
                // Cargar modelo de detección facial
                faceDetectionModel = await blazeface.load();
                
                updateStatus(modelStatus, 'Modelo TensorFlow: Cargado', true);
                loading.style.display = 'none';
                
                console.log('Modelo de detección facial cargado correctamente');
            } catch (error) {
                console.error('Error cargando modelos:', error);
                updateStatus(modelStatus, 'Modelo TensorFlow: Error', false);
                loading.style.display = 'none';
            }
        }
        
        // Aplicar efecto de blur a una región
        function applyBlurRegion(x, y, width, height, intensity = 10) {
            // Crear un canvas temporal para el blur
            const tempCanvas = document.createElement('canvas');
            const tempCtx = tempCanvas.getContext('2d');
            tempCanvas.width = width;
            tempCanvas.height = height;
            
            // Dibujar la región en el canvas temporal
            tempCtx.drawImage(canvas, x, y, width, height, 0, 0, width, height);
            
            // Aplicar múltiples pasadas de blur para mayor efecto
            for (let i = 0; i < intensity; i++) {
                tempCtx.filter = `blur(${intensity}px)`;
                tempCtx.drawImage(tempCanvas, 0, 0);
            }
            
            // Dibujar la región con blur de vuelta al canvas principal
            ctx.drawImage(tempCanvas, 0, 0, width, height, x, y, width, height);
        }
        
        // Aplicar efecto de pixelación a una región
        function applyPixelateRegion(x, y, width, height, pixelSize = 10) {
            // Obtener los datos de imagen de la región
            const imageData = ctx.getImageData(x, y, width, height);
            const data = imageData.data;
            
            // Aplicar pixelación
            for (let row = 0; row < height; row += pixelSize) {
                for (let col = 0; col < width; col += pixelSize) {
                    // Obtener el color promedio del bloque
                    let r = 0, g = 0, b = 0, count = 0;
                    
                    for (let y2 = 0; y2 < pixelSize && row + y2 < height; y2++) {
                        for (let x2 = 0; x2 < pixelSize && col + x2 < width; x2++) {
                            const idx = ((row + y2) * width + (col + x2)) * 4;
                            r += data[idx];
                            g += data[idx + 1];
                            b += data[idx + 2];
                            count++;
                        }
                    }
                    
                    r = Math.floor(r / count);
                    g = Math.floor(g / count);
                    b = Math.floor(b / count);
                    
                    // Aplicar el color promedio a todo el bloque
                    for (let y2 = 0; y2 < pixelSize && row + y2 < height; y2++) {
                        for (let x2 = 0; x2 < pixelSize && col + x2 < width; x2++) {
                            const idx = ((row + y2) * width + (col + x2)) * 4;
                            data[idx] = r;
                            data[idx + 1] = g;
                            data[idx + 2] = b;
                        }
                    }
                }
            }
            
            // Volver a dibujar la región pixelada
            ctx.putImageData(imageData, x, y);
        }
        
        // Procesar video frame por frame
        function processVideo(timestamp) {
            if (!stream) return;
            
            // Calcular FPS
            frameCount++;
            if (timestamp - lastTimestamp >= 1000) {
                const fps = Math.round((frameCount * 1000) / (timestamp - lastTimestamp));
                fpsCounter.textContent = fps;
                frameCount = 0;
                lastTimestamp = timestamp;
            }
            
            // Dibujar el video en el canvas
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
            
            // Aplicar filtro según selección
            switch(currentFilter) {
                case 'faceBlur':
                    applyFaceBlur();
                    break;
                case 'pixelate':
                    applyFacePixelation();
                    break;
                default:
                    // Sin filtro, solo dibujar video
                    break;
            }
            
            animationId = requestAnimationFrame(processVideo);
        }
        
        // Aplicar blur a los rostros detectados
        async function applyFaceBlur() {
            if (!faceDetectionModel) return;
            
            try {
                // Realizar detección facial
                const predictions = await faceDetectionModel.estimateFaces(video, false);
                
                // Actualizar contador de rostros
                faceCount.textContent = predictions.length;
                
                // Aplicar blur a cada rostro detectado
                for (const prediction of predictions) {
                    const start = prediction.topLeft;
                    const end = prediction.bottomRight;
                    const width = end[0] - start[0];
                    const height = end[1] - start[1];
                    
                    // Aumentar ligeramente el área para asegurar que cubra todo el rostro
                    const padding = 20;
                    const x = Math.max(0, start[0] - padding);
                    const y = Math.max(0, start[1] - padding);
                    const w = Math.min(canvas.width - x, width + padding * 2);
                    const h = Math.min(canvas.height - y, height + padding * 2);
                    
                    // Aplicar efecto de blur
                    applyBlurRegion(x, y, w, h, 15);
                }
            } catch (error) {
                console.error('Error en detección facial:', error);
            }
        }
        
        // Aplicar pixelación a los rostros detectados
        async function applyFacePixelation() {
            if (!faceDetectionModel) return;
            
            try {
                // Realizar detección facial
                const predictions = await faceDetectionModel.estimateFaces(video, false);
                
                // Actualizar contador de rostros
                faceCount.textContent = predictions.length;
                
                // Aplicar pixelación a cada rostro detectado
                for (const prediction of predictions) {
                    const start = prediction.topLeft;
                    const end = prediction.bottomRight;
                    const width = end[0] - start[0];
                    const height = end[1] - start[1];
                    
                    // Aumentar ligeramente el área para asegurar que cubra todo el rostro
                    const padding = 20;
                    const x = Math.max(0, start[0] - padding);
                    const y = Math.max(0, start[1] - padding);
                    const w = Math.min(canvas.width - x, width + padding * 2);
                    const h = Math.min(canvas.height - y, height + padding * 2);
                    
                    // Aplicar efecto de pixelación
                    applyPixelateRegion(x, y, w, h, 8);
                }
            } catch (error) {
                console.error('Error en detección facial:', error);
            }
        }
        
        // Configurar eventos
        startBtn.addEventListener('click', initCamera);
        stopBtn.addEventListener('click', stopCamera);
        
        faceBlurBtn.addEventListener('click', () => {
            currentFilter = 'faceBlur';
            updateStatus(filterStatus, 'Filtro: Blur Facial', true);
            faceBlurBtn.classList.add('active');
            pixelateBtn.classList.remove('active');
        });
        
        pixelateBtn.addEventListener('click', () => {
            currentFilter = 'pixelate';
            updateStatus(filterStatus, 'Filtro: Pixelar Rostros', true);
            pixelateBtn.classList.add('active');
            faceBlurBtn.classList.remove('active');
        });
        
        // Cargar modelos al iniciar la página
        window.addEventListener('load', loadModels);
        
        // Detener cámara al salir de la página
        window.addEventListener('beforeunload', stopCamera);
    </script>
</body>
</html>